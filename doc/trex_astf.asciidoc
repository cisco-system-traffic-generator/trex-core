TRex Advance stateful support
=============================
:author: TRex team
:email: trex.tgen@gmail.com 
:revnumber: 0.1
:quotes.++:
:numbered:
:web_server_url: https://trex-tgn.cisco.com/trex
:local_web_server_url: csi-wiki-01:8181/trex
:github_astf_path: https://github.com/cisco-system-traffic-generator/trex-core/tree/master/scripts/astf
:github_astf_examples_path: https://github.com/cisco-system-traffic-generator/trex-core/tree/master/scripts/automation/trex_control_plane/astf/examples
:github_stf_examples_path: https://github.com/cisco-system-traffic-generator/trex-core/tree/master/scripts/automation/trex_control_plane/stf/examples

:toclevels: 6

include::trex_ga.asciidoc[]

// PDF version - image width variable
ifdef::backend-docbook[]
:p_width: 450
:p_width_1: 200
:p_width_1a: 100
:p_width_1b: 50
:p_width_1c: 150
:p_width_lge: 500
endif::backend-docbook[]

// HTML version - image width variable
ifdef::backend-xhtml11[]
:p_width: 600
:p_width_1: 400
:p_width_1a: 650
:p_width_1a: 400
:p_width_1b: 200
:p_width_lge: 900
endif::backend-xhtml11[]



== Audience 

This document assumes basic knowledge of TRex, and assumes that TRex is installed and configured.
For information, see the link:trex_manual.html[manual], especially the material up to the link:trex_manual.html#_basic_usage[Basic Usage] section.
Consider this document as an extension to the manual, we might integrate both of them in the future. 

== Advance Stateful support 

=== Feature overview

TRex supports Stateless (STL) and Stateful (STF) modes.  

This document describes the new Advance Stateful mode (ASTF) that support TCP layer. 

The following UDP/TCP related use-cases will be addressed by ASTF mode. 

* Ability to work when the DUT terminates the TCP stack (e.g. compress/uncompress, see figure 1). In this case there is a different TCP session on each side, but L7 data are *almost* the same.

image::images/t_c2.png[title="DUT is TCP proxy",align="center",width={p_width}, link="images/t_c2.png"]

* Ability to work in either client mode or server mode. This way TRex client side could be installed in one physical location on the network and TRex server in another. figure 2 shows such an example

image::images/t_c3.png[title="C/S mode",align="center",width={p_width}, link="images/t_c2.png"]

* Performance and scale
** High bandwidth - ~200gb/sec with many realistic flows (not one elephant flow)
** High connection rate - order of MCPS
** Scale to millions of active established flows
* Simulate latency/jitter/drop in high rate
* Emulate L7 application, e.g. HTTP/HTTPS/Citrix- there is no need to implement the exact application.
* Simulate L7 application on top of TLS using OpenSSL
* BSD baseTCP implementation 
* Ability to change fields in the L7 stream application - for example, change HTTP User-Agent field
* Interactive support - Fast Console,  GUI 
* TCP/UDP/Application statistics (per client side/per template/per port)
* Verify incoming IP/TCP/UDP checksum 
* Python 2.7/3.0 Client API 
* Ability to build a realistic traffic profile that includes TCP and UDP protocols (e.g. SFR EMIX)
* IPv6/IPv4 
* Fragmentation support 
* Accurate latency for TCP flows - SYN/SYN ACK and REQ/RES latency histogram, usec resolution

[NOTE] 
=====================================================================
Not all the features will be available in the first release. 
=====================================================================

==== Status

WARNING: The ASTF version is in pre-alpha state and it is still under development. There are many known issues that we are working to fix, however you are welcome to report new issues  

===== What works in the current version 

* Profile with multi templates of TCP
* IPv4 and IPv6 
* VLAN configuration 
* One DP core per dual-ports
* Enable client only or server only or both
* High scale with flows/BW/PPS
* Ability to change the TCP configuration (default MSS/buffer size/RFC enabled etc)
* Ability to change IPv4/IPv6 configuration like default TOS etc
* Flexible tuple generator 
* Automation support (using STF framework)

===== Known bugs

* Mellanox CX-4/5 out of order issue see link:https://trex-tgn.cisco.com/youtrack/issue/trex-481[trex-481]

===== Limitation/feature that wasn't implemented/exposed yet

* IPv6 traffic is assumed to be generated by TRex itself (only the 32bit LSB is taken as a key)
* UDP is not supported 
* One DP core per dual-ports
* Simulation of Jitter/Latency/drop
* Interactive support - work with Console to start/stop/get a statistic. This will enable the L2 emulation framework  (e.g. Wireless AP)
* Field Engine support - ability to change a field inside the stream 
* OpenSSL integration  
* Accurate latency for TCP session. Measure sample of the flows in EF/low latency queue. Measure the SYN=SYN-ACK and REQ-RES latency histogram 
* Fragmentation is not supported 
* TCP statistic per template 
* Tunable profile support -- give a few tunable from console to the python profile (e.g. --total-bw 10gbps)

==== Can we address the above requirements using existing DPDK TCP stacks?

Can we leverage one of existing DPDK TCP stacks for our need? The short answer is no. 
We chose to take a BSD4.4 original code base with FreeBSD bug fixes patches and improve the scalability to address our needs. 
More on the reasons why in the following sections, but let me just say the above TCP DPDK stacks are optimized for real client/server application/API while in most of our traffic generation use cases, *most* of the traffic is known ahead of time allowing us to do much better.
let's take a look into what are the main properties of TRex TCP module and understand what were the main challenges we tried to solve.

==== The main properties of scalable TCP for traffic generation

* Interact with DPDK API for batching of packets
* Multi-instance - lock free. Each thread will get its own TCP context with local counters/configuration, flow-table etc ,RSS
* Async, Event driven - No OS API/threads needed
** Start write buffer
** Continue write
** End Write
** Read buffer /timeout
** OnConnect/OnReset/OnClose
* Accurate with respect to TCP RFCs - at least derive from BSD to be compatible - no need to reinvent the wheel
* Enhanced tcp statistics - as a  traffic generator we need to gather as many statistics as we can, for example per template tcp statistics.
* Ability to save descriptors for better simulation of latency/jitter/drop

The folowing figure shows the block diagram of new TRex TCP design

image::images/t_c4.png[title="Stack",align="center",width=200, link="images/t_c4.png"]

And now lets proceed to our challenges, let me just repeat the objective of TRex, it is not to reach a high rate with one flow, it is to simulate a realistic network with many clients using small flows. Let's try to see if we can solve the scale of million of flows.

==== Tx Scale to millions of flows

image::images/t_c5.png[title="TCP Tx side",align="center",width={p_width}, link="images/t_c5.png"]

Most TCP stacks have an API that allow the user to provide his buffer for write (push) and the TCP module will save them until the packets are acknowledged by the remote side. Figure 4 shows how one TX queue of one TCP flow looks like on the Tx side. This could create a scale issue in worst case. Let's assume we need 1M active flows with 64K TX buffer (with reasonable buffer, let's say RTT is small). The worst case buffer in this case could be
1M x 64K * mbuf-factor (let's assume 2) = 128GB. The mbuf resource is expensive and needs to be allocated ahead of time.
the solution we chose for this problem (which from a traffic generator's point of view) is to change the API to be a poll API, meaning TCP will request the buffers from the application layer only when packets need to be sent (lazy). Now because most of the traffic is constant in our case, we could save a lot of memory and have an unlimited scale (both of flows and tx window).

[NOTE] 
=====================================================================
This optimization won't work with TLS since constant sessions will have new data
=====================================================================

==== Rx Scale to millions of flows

image::images/t_c6.png[title="Example of multiple streams",align="center",width={p_width}, link="images/t_c6.png"]
                                            
The same problem exists in the case of reassembly in the rx side, in worst case there is a need to store a lot of memory in reassembly queue. To fix this we can add a filter API for the application layer. Let's assume that the application layer can request only a partial portion of the data since the rest is less important, for example data in offset of 61K-64K and only in case of restransmission (simulation). In this case we can give the application layer only the filtered data that is really important to it and still allow TCP layer to work in the same way from seq/ack perspective.

[NOTE] 
=====================================================================
This optimization won't work with TLS since constant sessions will have new data
=====================================================================
            
==== Simulation of latency/jitter/drop in high scale

image::images/t_c7.png[title="TCP Rx side",align="center",width={p_width}, link="images/t_c7.png"]

There is a requirement to simulate latency/jitter/drop in the network layer. Simulating drop in high rate it is not a problem, but simulating latency/jitter in high rate is a challenge because there is a need to queue a high number of packets. See figure 6 on the left.
A better solution is to queue a pointer to both the TCP flow and the TCP descriptor (with TSO information) and only when needed (i.e. when it has already left the tx queue) build the packet again (lazy). The memory footprint in this case can be reduced dramatically.

==== Emulation of L7 application

To emulate L7 application on top of the TCP layer we can define a set of simple operations. 
The user would be able to build an application emulation layer from Python API or by a utility that we will provide that will analyze a pcap file and convert it to TCP operations. 
Another thing that we can learn from pcap is the TCP parameters like MSS/Window size/Nagel/TCP options etc
Let's give a simple example of a L7 emulation of HTTP Client and HTTP Server

.HTTP Client
[source,python]
----
send(request,len=100)
wait_for_response(len<=1000)
delay(random(100-1000)*usec)
send(request2,len=200)
wait_for_response(len<=2000)
close()
----

.HTTP Server
[source,python]
----
wait_for_request(len<=100)
send_ response(data,len=1000)
wait_for_request(len<=200)
send_ response(data,len=2000)
close()
----
 
This way both Client and Server don't need to know the exact application protocol, they just need to have the same story/program. In real HTTP server, the server parses the HTTP requeset, learns the Content-Length field, waits for  the rest of the data and finally retrieves the information from disk. With our L7 emulation there is no need. Even in cases where the data length is changed (for example NAT/LB that changes the data length) we can give some flexibility within the program on the value range of the length
In case of UDP it would be message base protocols like send_msg/wait_for_msg etc. with UDP we will have the ability to wait for a few packets. 

==== Stateful(STF) vs Advance Stateful (ASTF)

* Same Flexible tuple generator 
* Same Clustering mode 
* Same VLAN support
* NAT - no need for complex learn mode. ASTF supports NAT64 out of the box.
* Flow order. ASTF has inherent ordering verification using the TCP layer. It also checks IP/TCP/UDP checksum out of the box.
* Latency measurement is supported in both.
* In ASTF mode, you can't control the IPG, less predictable (concurrent flows is less deterministic)

=== ASTF package folders 

[cols="5,5", options="header",width="100%"]
|=============================
| Location        | Description   
| /astf           | astf native (py) profiles 
| /automation/trex_control_plane/astf/examples     | automation examples
| /automation/trex_control_plane/astf/trex_astf_lib     | astf lib compiler (convert py to JSON)
| /automation/trex_control_plane/stf     | stf automation (used by astf mode)
| /automation/trex_control_plane/astf/examples     | stf automation  example
|=============================


=== Getting started Tutorials

The tutorials in this section demonstrate basic TRex ASTF use cases. Examples include common and moderately advanced TRex concepts.

==== Tutorial: Prepare TRex configuration file 

*Goal*:: Define the TRex physical or virtual ports and create configuration file.

Follow this chapter  link:trex_manual.html#_first_time_running[first time configuration ]


==== Tutorial: run TRex with simple HTTP profile   

*Goal*:: 

Send a simple HTTP flows

*Traffic profile*::  

The following profile defines one template of HTTP 

*File*:: 

link:{github_astf_path}/http_simple.py[astf/http_simple.py]

[source,python]
----
from trex_astf_lib.api import *


class Prof1():
    def __init__(self):
        pass

    def get_profile(self):
        # ip generator
        ip_gen_c = ASTFIPGenDist(ip_range=["16.0.0.0", "16.0.0.255"], 
                                 distribution="seq")
        ip_gen_s = ASTFIPGenDist(ip_range=["48.0.0.0", "48.0.255.255"], 
                                  distribution="seq")
        ip_gen = ASTFIPGen(glob=ASTFIPGenGlobal(ip_offset="1.0.0.0"),      <1>
                           dist_client=ip_gen_c,
                           dist_server=ip_gen_s)

        return ASTFProfile(default_ip_gen=ip_gen,
                            cap_list=[ASTFCapInfo(
                                      file="../avl/delay_10_http_browsing_0.pcap"
                                      cps=1)
                                     ])                                    <2>


def register():
    return Prof1()

----
<1> Define the tuple generator range for client side and server side
<2> The template list with relative CPS (connection per second) 


*Running TRex with this profile*::   

[source,bash]
----
[bash]>sudo ./t-rex-64 -f astf/http_simple.py -m 1000 -d 1000 -c 1 --astf -l 1000 -k 10  
----

* `--astf` is mandatory to enable ASTF mode 
* (Optional) Use `-c` to 1, in this version it is limited to 1 core for each dual interfaces 
* (Optional) Use `--cfg` to specify a different configuration file. The default is link:trex_manual.html#_create_minimum_configuration_file[/etc/trex_cfg.yaml].


pressing `*t*' while traffic is running you can see the TCP JSON counters as table

[source,bash]
----


                   |     client  |        server |  
 --------------------------------------------------------------------------------
   m_active_flows  |      39965  |        39966  |  active flows
      m_est_flows  |      39950  |        39952  |  active est flows
     m_tx_bw_l7_r  | 31.14 Mbps  |    4.09 Gbps  |  tx bw
     m_rx_bw_l7_r  |  4.09 Gbps  |   31.14 Mbps  |  rx bw
       m_tx_pps_r  |140.36 Kpps  |  124.82 Kpps  |  tx pps
       m_rx_pps_r  |156.05 Kpps  |  155.87 Kpps  |  rx pps
       m_avg_size  |    1.74 KB  |      1.84 KB  |  average pkt size
                -  |        ---  |          ---  |  
              TCP  |        ---  |          ---  |  
                -  |        ---  |          ---  |  
 tcps_connattempt  |      73936  |            0  |  connections initiated
     tcps_accepts  |          0  |        73924  |  connections accepted
    tcps_connects  |      73921  |        73910  |  connections established
      tcps_closed  |      33971  |        33958  |  conn. closed (includes drops)
   tcps_segstimed  |     213451  |       558085  |  segs where we tried to get rtt
  tcps_rttupdated  |     213416  |       549736  |  times we succeeded
      tcps_delack  |     344742  |            0  |  delayed acks sent
    tcps_sndtotal  |     623780  |       558085  |  total packets sent
     tcps_sndpack  |      73921  |       418569  |  data packets sent
     tcps_sndbyte  |   18406329  |   2270136936  |  data bytes sent
     tcps_sndctrl  |      73936  |            0  |  control (SYN,FIN,RST) packets sent
     tcps_sndacks  |     475923  |       139516  |  ack-only packets sent 
     tcps_rcvpack  |     550465  |       139502  |  packets received in sequence
     tcps_rcvbyte  | 2269941776  |     18403590  |  bytes received in sequence
  tcps_rcvackpack  |     139495  |       549736  |  rcvd ack packets
  tcps_rcvackbyte  |   18468679  |   2222057965  |  tx bytes acked by rcvd acks
     tcps_preddat  |     410970  |            0  |  times hdr predict ok for data pkts 
   tcps_rcvoopack  |          0  |            0  |  *out-of-order packets received   #<1>
                -  |        ---  |          ---  |  
       Flow Table  |        ---  |          ---  |  
                -  |        ---  |          ---  |  
   redirect_rx_ok  |          0  |            1  |  redirect to rx OK
       
----
<1> Counters with asterisk prefix (*) means that there is some kind of error, see counters description for more information

*Discussion*::

When a template with pcap file is specified, like in this example the python code analyzes the L7 data of the pcap file and TCP configuration and build a JSON that represent  
* The client side application 
* The server side application (opposite from client)
* TCP configuration for each side 

.Client side pseudo code
[source,python]
----

template = choose_template()                                         <1>

src_ip,dest_ip,src_port = generate from pool of client
dst_port                = template.get_dest_port()

s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)                <2>

s.connect(dest_ip,dst_port)                                          <3>

# program                                                            <4>
s.write(template.request)      #write the following taken from the pcap file

                               # GET /3384 HTTP/1.1
                               # Host: 22.0.0.3
                               # Connection: Keep-Alive
                               # User-Agent: Mozilla/4.0 
                               # Accept: */*
                               # Accept-Language: en-us
                               # Accept-Encoding: gzip, deflate, compress
         

s.read(template.request_size)  # wait for 32K bytes and compare some of it 

                               #HTTP/1.1 200 OK
                               #Server: Microsoft-IIS/6.0
                               #Content-Type: text/html
                               #Content-Length: 32000
                               # body .. 
 

s.close();

----
<1>  Tuple-generator is used to generate tuple for client  and server side and choose a template 
<2>  Flow is created 
<3>  Connect to the server 
<4>  Run the program base on JSON (in this example created from the pcap file)


.Server side pseudo code
[source,python]
----

# if this is SYN for flow that already exist, let TCP handle it

if ( flow_table.lookup(pkt) == False ) :
    # first SYN in the right direction with no flow 
    compare (pkt.src_ip/dst_ip to the generator ranges) # check that it is in the range or valid server IP (src_ip,dest_ip)
    template= lookup_template(pkt.dest_port) #get template for the dest_port
    
    # create a socket for TCP server   
    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)               <1>

    # bind to the port  
    s.bind(pkt.dst_ip, pkt.dst_port)
    
    s.listen(1)
    
    #program of the template                                            <2>
    s.read(template.request_size)      # just wait for x bytes, don't check them 
    
                                       # GET /3384 HTTP/1.1
                                       # Host: 22.0.0.3
                                       # Connection: Keep-Alive
                                       # User-Agent: Mozilla/4.0 ..
                                       # Accept: */*
                                       # Accept-Language: en-us
                                       # Accept-Encoding: gzip, deflate, compress

    
    s.write(template.response)        # just wait for x bytes, 
                                      # don't check them (TCP check the seq and checksum)
        
                                      #HTTP/1.1 200 OK
                                      #Server: Microsoft-IIS/6.0
                                      #Content-Type: text/html
                                      #Content-Length: 32000
                                      # body .. 

    s.close()    

----
<1> As you can see from the pseudo code there is no need to open all the servers ahead of time, we open and allocate socket only when packet match the criteria of server side
<2> the program is the opposite of the client side.
    
The above is just a pseudo code that was created to explain how logically TRex works. It was simpler to show a pseudo code that runs in one thread in blocking  fashion, but in practice it is run in an event driven and many flows can multiplexed in high performance and scale. 
The L7 program can be written using Python API (it is compiled to micro-code event driven by TRex server).

==== Tutorial: Profile with two templates 

*Goal*:: 

Simple browsing, HTTP and HTTPS flow. In this example, each template has different destination port (80/443)

*Traffic profile*::  

the profile include HTTP and HTTPS profile. each second there would be 2 HTTPS flows and 1 HTTP flow. 

*File*:: 

link:{github_astf_path}/http_https.py[astf/http_https.py]

[source,python]
----
class Prof1():
        def __init__(self):
        pass
        
        def get_profile(self):
        # ip generator
        ip_gen_c = ASTFIPGenDist(ip_range=["16.0.0.0", "16.0.0.255"], 
                                 distribution="seq")
        ip_gen_s = ASTFIPGenDist(ip_range=["48.0.0.0", "48.0.255.255"], 
                                 distribution="seq")
        ip_gen = ASTFIPGen(glob=ASTFIPGenGlobal(ip_offset="1.0.0.0"),
                           dist_client=ip_gen_c,
                           dist_server=ip_gen_s)
        
        return ASTFProfile(default_ip_gen=ip_gen,
                            cap_list=[
                             ASTFCapInfo(file="../avl/delay_10_http_browsing_0.pcap",
                                         cps=1),    <1>
                             ASTFCapInfo(file="avl/delay_10_https_0.pcap",
                                         cps=2)     <2>
                                      ])                     


def register():
    return Prof1()
----
<1> HTTP template 
<2> HTTPS template 

*Discussion*::

The server side chooses the template base on the *destination* port. Because each template has a unique destination port (80/443) there is nothing to do.  In the next example we will show what to do in case both templates has the same destination port.
From the client side, the scheduler will schedule in each second 2 HTTPS flows and 1 HTTP flow base on the CPS


==== Tutorial: Profile with two templates same ports

*Goal*:: 

create profile with two HTTP templates. In this example, both templates has the same destination port (80)

*Traffic profile*::  

The profile includes same HTTP profile only for demonstration. 

*File*:: 

[source,python]
----
class Prof1():
    def __init__(self):
        pass

    def get_profile(self):
        # ip generator
        ip_gen_c = ASTFIPGenDist(ip_range=["16.0.0.0", "16.0.0.255"], 
                                 distribution="seq")
        ip_gen_s = ASTFIPGenDist(ip_range=["48.0.0.0", "48.0.255.255"], 
                                  distribution="seq")
        ip_gen = ASTFIPGen(glob=ASTFIPGenGlobal(ip_offset="1.0.0.0"),
                           dist_client=ip_gen_c,
                           dist_server=ip_gen_s)

        return ASTFProfile(default_ip_gen=ip_gen,
                            cap_list=[ASTFCapInfo(file="../avl/delay_10_http_browsing_0.pcap",
                                      cps=1),          <1>
                                      ASTFCapInfo(file="../avl/delay_10_http_browsing_0.pcap",
                                      cps=2,port=8080) <2>
                                     ])  


def register():
    return Prof1()
----
<1> HTTP template 
<2> HTTP template override the pcap file destination port

*Discussion*::

In a real world the same server can handle many types of transaction on the same port base on the request. In this TRex version we have this limitation as it is only an emulation. next we would add better engine that could associate the template base on server Ip-port socket or by L7 data 

==== Tutorial: Profile with two range of tuple generator 

*Goal*:: 

create a profile with two set of client/server tuple pools

*Traffic profile*::  

The profile includes same HTTP template for demonstration. 

*File*:: 

link:{github_astf_path}/http_simple_different_ip_range.py[astf/http_simple_different_ip_range.py]


[source,python]
----

class Prof1():
    def __init__(self):
        pass  # tunables

    def create_profile(self):
        ip_gen_c1 = ASTFIPGenDist(ip_range=["16.0.0.1", "16.0.0.255"], 
                                  distribution="seq")      <1>
        ip_gen_s1 = ASTFIPGenDist(ip_range=["48.0.0.1", "48.0.255.255"], 
                                  distribution="seq")
        ip_gen1 = ASTFIPGen(glob=ASTFIPGenGlobal(ip_offset="1.0.0.0"),
                            dist_client=ip_gen_c1,
                            dist_server=ip_gen_s1)

        ip_gen_c2 = ASTFIPGenDist(ip_range=["10.0.0.1", "10.0.0.255"], 
                                  distribution="seq")      <2>
        ip_gen_s2 = ASTFIPGenDist(ip_range=["20.0.0.1", "20.255.255"], 
                                  distribution="seq")
        ip_gen2 = ASTFIPGen(glob=ASTFIPGenGlobal(ip_offset="1.0.0.0"),
                            dist_client=ip_gen_c2,
                            dist_server=ip_gen_s2)

        profile = ASTFProfile(cap_list=[
            ASTFCapInfo(file="../cap2/http_get.pcap", 
                        ip_gen=ip_gen1),                          <3> 
            ASTFCapInfo(file="../cap2/http_get.pcap", 
                        ip_gen=ip_gen2, port=8080)                <4>
            ])

        return profile
----
<1> define generator range 1
<2> define generator range 2
<3> assigne generator range 1 to the first template 
<4> assigne generator range 2 to the second template 

*Discussion*::

The tuple generator ranges should not overlap 

==== Tutorial: run with IPv6 traffic 

[source,bash]
----
[bash]>sudo ./t-rex-64 -f astf/http_simple.py -m 1000 -d 1000 -c 1 --astf -l 1000 --ipv6
----

just add `--ipv6' to the CLI. The IPv6 packets will be look like this  

[source,bash]
----
::x.x.x.x where LSB is IPv4 addrees 
----

==== Tutorial: Python automation 

*Goal*:: Simple automation test using Python from a local or remote machine 

*Directories*::

Python API examples: `automation/trex_control_plane/stf/examples`.

Python API library: `automation/trex_control_plane/stf/trex_stl_lib`.


We are using for the first version the same STF python API framework, we are working to move to interactive mode like the STL mode

image::images/trex_control_plane_modules.png[title="RPC Server Components",align="center",width={p_width}, link="images/trex_architecture_01.png"]

*File*:: link:{github_stf_examples_path}/stf_tcp.py[stl_tcp.py]

.ASTF automation 
[source,python]
----

import argparse
import stf_path
from trex_stf_lib.trex_client import CTRexClient       <1>
from pprint import pprint


def validate_tcp (tcp_s):
    if 'err' in tcp_s :
        pprint(tcp_s);
        return(False);
    return True;


def run_stateful_tcp_test(server):

    trex_client = CTRexClient(server)

    trex_client.start_trex(
            c = 1, # limitation for now                 <2>
            m = 1000,
            f = 'astf/http_simple.py',                  <3>
            k=10,
            d = 20,
            l = 1000,
            astf =True, #enable TCP                     <4>
            nc=True
            )

    result = trex_client.sample_to_run_finish()

    c = result.get_latest_dump()
    pprint(c["tcp-v1"]["data"]);                        <5>
    tcp_c= c["tcp-v1"]["data"]["client"];
    if not validate_tcp(tcp_c):
       return False
    tcp_s= c["tcp-v1"]["data"]["server"];
    if not validate_tcp(tcp_s):
        return False




if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="tcp example")

    parser.add_argument('-s', '--server',
                        dest='server',
                        help='Remote trex address',
                        default='127.0.0.1',
                        type = str)
    args = parser.parse_args()

    if run_stateful_tcp_test(args.server):
        print("PASS");

----
<1> Imports the old trex_stf_lib 
<2> force one DP core, limitation for now
<3> load a astf profile 
<4> enable astf mode 
<5> check astf client server counters.

See link:cp_docs/index.html[TRex Stateful Python API] for details about using the Python APIs. 

.ASTF JSON format
[source,python]
----

{'client': {'all': {
                    'm_active_flows': 6662,
                    'm_avg_size': 1834.3,
                    },
            'err' : { 'some erorr counter name' : 'descriptiuon of the counter'} <1>
            },
 'server': { 'all': {},
             'err' : {}    
           }
 }
----
<1> 'err' object won't be exist in case of no error 


.ASTF  example of ASTF counters with no errors
[source,python]
----

{'client': {'all': {'__last': 0,
                    'm_active_flows': 6662,
                    'm_avg_size': 1834.3,
                    'm_est_flows': 6657,
                    'm_rx_bw_l7_r': 369098181.6,
                    'm_rx_pps_r': 12671.8,
                    'm_tx_bw_l7_r': 2804666.1,
                    'm_tx_pps_r': 12672.2,
                    'redirect_rx_ok': 120548,
                    'tcps_closed': 326458,
                    'tcps_connattempt': 333120,
                    'tcps_connects': 333115,
                    'tcps_delack': 1661439,
                    'tcps_preddat': 1661411,
                    'tcps_rcvackbyte': 83275862,
                    'tcps_rcvackpack': 664830,
                    'tcps_rcvbyte': 10890112648,
                    'tcps_rcvpack': 2326241,
                    'tcps_rttupdated': 997945,
                    'tcps_segstimed': 997962,
                    'tcps_sndacks': 2324887,
                    'tcps_sndbyte': 82945635,
                    'tcps_sndctrl': 333120,
                    'tcps_sndpack': 333115,
                    'tcps_sndtotal': 2991122}},
 'server': {'all': {'__last': 0,
                    'm_active_flows': 6663,
                    'm_avg_size': 1834.3,
                    'm_est_flows': 6657,
                    'm_rx_bw_l7_r': 2804662.9,
                    'm_rx_pps_r': 14080.0,
                    'm_tx_bw_l7_r': 369100825.2,
                    'm_tx_pps_r': 11264.0,
                    'redirect_rx_ok': 120549,
                    'tcps_accepts': 333118,
                    'tcps_closed': 326455,
                    'tcps_connects': 333112,
                    'tcps_rcvackbyte': 10882823775,
                    'tcps_rcvackpack': 2657980,
                    'tcps_rcvbyte': 82944888,
                    'tcps_rcvpack': 664836,
                    'tcps_rttupdated': 2657980,
                    'tcps_segstimed': 2659379,
                    'tcps_sndacks': 664842,
                    'tcps_sndbyte': 10890202264,
                    'tcps_sndpack': 1994537,
                    'tcps_sndtotal': 2659379}}}

----

in case there is no errors the 'err' object won't be there. in case of an error counters the 'err' section will include the counter and the description. the 'all' section includes the good and error counters value
                
==== Tutorial: Simple simulator 

*Goal*:: Use the TRex ASTF simple simulator.

The TRex package includes a simulator tool, `astl-sim`. The simulator operates as a Python script that calls an executable. The platform requirements for the simulator tool are the same as for TRex.

The TRex simulator can:

Demonstrates the most basic use case using TRex simulator. In this simple simulator there is *one* client flow and *one* server flow and there is *only* one template (the first one). 
the objective of this simulator is to verify the TCP layer and application layer. 
In this simulator, it is possible to simulate many abnormal cases for example:

* Drop of specific packets. 
* Change of packet information (e.g. wrong  sequence numbers)
* Man in the middle RST and redirect 
* Keepalive timers.
* Set the round trip time  
* Convert the profile to JSON format 

We didn't expose all the capability of the simulator tool but you could debug the emulation layer using this tool and explore the pcap output files. 

Example traffic profile: 

*File*:: link:{github_astf_path}/http_simple.py[stl/http_simple.py]

The following runs the traffic profile through the TRex simulator, and storing the output in a pcap file.

[source,bash]
----
[bash]>./astf-sim -f astf/http_simple.py -o b
----

those are the pcap file that generated:
 
* b_c.pcap  client side pcap 
* b_s.pcap  server side pcap 

Contents of the output pcap file produced by the simulator in the previous step:

Adding `--json` displays the details of the JSON profile

[source,python]
----
[bash]>./astf-sim -f astf/http_simple.py --json
{
    "templates": [                               <1>
        {
            "client_template": {
                "tcp_info": {
                    "index": 0
                },
                "port": 80,                # dst port
                "cps": 1,                  # rate in CPS
                "program_index": 0,        # index into program_list
                "cluster": {},
                "ip_gen": {
                    "global": {
                        "ip_offset": "1.0.0.0"
                    },
                    "dist_client": {
                        "index": 0        # index into ip_gen_dist_list
                    },
                    "dist_server": {
                        "index": 1        # index into ip_gen_dist_list
                    }
                }
            },
            "server_template": {
                "program_index": 1,
                "tcp_info": {
                    "index": 0
                },
                "assoc": [
                    {
                        "port": 80        # Which dst port will be associated with this template
                    }
                ]
            }
        }
    ],
    "tcp_info_list": [                          <2>
        {
            "options": 0,
            "port": 80,
            "window": 32768
        }
    ],
    "program_list": [                           <3>
        {
            "commands": [
                {
                    "name": "tx",
                    "buf_index": 0            # index into "buf_list"
                },
                {
                    "name": "rx",
                    "min_bytes": 32089
                }
            ]
        },
        {
            "commands": [
                {
                    "name": "rx",
                    "min_bytes": 244
                },
                {
                    "name": "tx",
                    "buf_index": 1            # index into "buf_list"
                }
            ]
        }
    ],
    "ip_gen_dist_list": [                      <4>
        {
            "ip_start": "16.0.0.1",
            "ip_end": "16.0.0.255",
            "distribution": "seq"
        },
        {
            "ip_start": "48.0.0.1",
            "ip_end": "48.0.255.255",
            "distribution": "seq"
        }
    ],
    "buf_list": [                              <5>
        "R0VUIC8zMzg0IEhUVFAvMS4xDQpIb3",
        "SFRUUC8xLjEgMjAwIE9LDQpTZXJ2ZX"
    ]
}
----
<1> A list of templates with the properties of each template 
<2> A list of indirect distinct tcp/ip options
<3> A list of indirect distinct emulation programs 
<4> A list of indirect distinct tuple generator 
<5> A list of indirect distinct L7 buffers, used by emulation program (indirect) ( e.g. "buf_index": 1)


[NOTE] 
=====================================================================
we might change the JSON format in the future as this is a first version 
=====================================================================


==== Tutorial: advanced simulator 

*Goal*:: Use the TRex ASTF advanced simulator.

It is like the simple simulator but simulate multiple templates and flows exacly like TRex server would do with one DP core 

[source,bash]
----
[bash]>./astf-sim -f astf/http_simple.py --full -o b.pcap 
----


* Use `--full' initiated the full simulation mode
* b.pcap output pcap file will be generated, it is the client side multiplex pcap
* There is no server side pcap file in this simulation because we are not simulating latency/jitter/drop in this case so the server should be the same as client side.

another example that will run sfr profile in release mode and will show the counters 

[source,bash]
----
[bash]>./astf-sim -f astf/sfr.py --full -o o.pcap -d 1 -r -v 
----


=== Performance 

see link:trex_astf_vs_nginx.html[ASTF Performance]

=== Traffic profile reference 

link:cp_astf_docs/index.html[python index]

=== Counters reference 

* Client side aggregates the ASTF counters from all client ports in the system (e.g. 0/2/4)
* Server side aggregates the ASTF counters from all client ports in the system (e.g. 1/3/5)

.General counters 
[options="header",cols="1,^1,5"]
|=================
| Counter           |Error |Description  
|    active_flows   || active flows (established + non-established)
|    est_flows      || active established flows 
|    tx_bw_l7       || tx acked L7 bandwidth in bps 
|    tx_bw_l7_total || tx total L7 bandwidth sent in bps 
|    rx_bw_l7       || rx acked L7 bandwidth in bps 
|    tx_pps_r       || tx bandwidth in pps  (TSO packets)     *1*
|    rx_pps_r       || rx bandwidth in pps  (LRO packets)     *2*
|    avg_size       || average pkt size (base on TSO/LRO) see *1*/*2*
|    tx_ratio       || ratio betwean tx_bw_l7_r and tx_bw_l7_total_r 100% means no retransmition
|=================

.TCP counters 
[options="header",cols="1,^1,5"]
|=================
| Counter           |Error |Description  
|   tcps_connattempt || connections initiated
|   tcps_accepts     || connections accepted
|   tcps_connects    || connections established
|   tcps_closed      || conn. closed (includes drops) - this counter could be higher than tcps_connects for client side as flow could be be dropped before establishment 
|   tcps_segstimed   || segs where we tried to get rtt
|   tcps_rttupdated  || times we succeeded
|   tcps_delack      || delayed acks sent
|   tcps_sndtotal    || total packets sent (TSO)
|   tcps_sndpack     || data packets sent  (TSO)
|   tcps_sndbyte     || data bytes sent by application 
|   tcps_sndbyte_ok  || data bytes sent by tcp layer could be more than tcps_sndbyte (asked by application)
|   tcps_sndctrl     || control (SYN,FIN,RST) packets sent
|   tcps_sndacks     || ack-only packets sent 
|   tcps_rcvtotal    || total packets received (LRO)
|   tcps_rcvpack     || packets received in sequence (LRO)
|   tcps_rcvbyte     || bytes received in sequence
|   tcps_rcvackpack  || rcvd ack packets (LRO)        *2*         
|   tcps_rcvackbyte  || tx bytes acked by rcvd acks (should be the same as tcps_sndbyte )
|   tcps_rcvackbyte_of  || tx bytes acked by rcvd acks -overflow ack
|   tcps_preddat     || times hdr predict ok for data pkts 
|   tcps_drops       |*| connections dropped
|   tcps_conndrops   |*| embryonic connections dropped
|   tcps_timeoutdrop |*| conn. dropped in rxmt timeout
|   tcps_rexmttimeo  |*| retransmit timeouts
|   tcps_persisttimeo|*| persist timeouts 
|   tcps_keeptimeo   |*| keepalive timeouts
|   tcps_keepprobe   |*| keepalive probes sent
|   tcps_keepdrops   |*| connections dropped in keepalive
|   tcps_sndrexmitpack |*| data packets retransmitted
|   tcps_sndrexmitbyte |*| data bytes retransmitted
|   tcps_sndprobe      || window probes sent
|   tcps_sndurg        || packets sent with URG only
|   tcps_sndwinup      || window update-only packets sent
|   tcps_rcvbadoff    |*| packets received with bad offset
|   tcps_rcvshort     |*| packets received too short
|   tcps_rcvduppack   |*| duplicate-only packets received
|   tcps_rcvdupbyte   |*| duplicate-only bytes received 
|   tcps_rcvpartduppack |*| packets with some duplicate data
|   tcps_rcvpartdupbyte |*| dup. bytes in part-dup. packets
|   tcps_rcvoopackdrop  |*| OOO packet drop due to queue len
|   tcps_rcvoobytesdrop |*| OOO bytes drop due to queue len
|   tcps_rcvoopack      |*| out-of-order packets received
|   tcps_rcvoobyte      |*| out-of-order bytes received
|   tcps_rcvpackafterwin |*| packets with data after window
|   tcps_rcvbyteafterwin |*| ,"bytes rcvd after window
|   tcps_rcvafterclose  |*| packets rcvd after close
|   tcps_rcvwinprobe || rcvd window probe packets
|   tcps_rcvdupack |*| rcvd duplicate acks
|   tcps_rcvacktoomuch |*|rcvd acks for unsent data
|   tcps_rcvwinupd ||  rcvd window update packets
|   tcps_pawsdrop|*|  segments dropped due to PAWS
|   tcps_predack |*| times hdr predict ok for acks
|   tcps_persistdrop |*|timeout in persist state
|   tcps_badsyn |*|  bogus SYN, e.g. premature ACK
|   tcps_reasalloc |*| allocate tcp reasembly ctx
|   tcps_reasfree |*| free tcp reasembly ctx
|   tcps_nombuf |*| no mbuf for tcp - drop the packets
|=================

.Flow table counters 
[options="header",cols="1,^1,5"]
|=================
| Counter           |Error |Description  
|    err_cwf     |*| client pkt that does not match a flow could no happen in loopback. Could happen if DUT generated a packet after TRex close the flow
|    err_no_syn  |*| server first flow packet with no SYN
|    err_len_err |*| pkt with L3 length error 
|    err_no_tcp  |*| no tcp packet- dropped 
|    err_no_template |*| server can't match L7 template no destination port or IP range 
|    err_no_memory |*| no heap memory for allocating flows
|    err_dct      |*| duplicate flow can't happen
|    err_l3_cs|*| ipv4 checksum error
|    err_l4_cs|*| tcp/udp checksum error (in case NIC support it)
|    err_redirect_rx |*| redirect to rx error 
|    redirect_rx_ok || redirect to rx OK
|=================

*1*:: 

see link:https://en.wikipedia.org/wiki/Large_send_offload[TSO], we count the number of TSO packets with NIC that support that, this number could be significantly smaller than the real number of packets

*2*:: 

see link:https://en.wikipedia.org/wiki/Large_receive_offload[LRO], we count the number of LRO packets with NIC that support that, this number could be significantly smaller than the real number of packets

*Important information*:: 
* It hard to compare the number of TCP tx (client) TSO packets to rx (server) LRO packets as it might be different. The better approach would be to compare the number of bytes 
** client.tcps_rcvackbyte == server.tcps_rcvbyte and vice versa (updload and download)
** tcps_sndbyte == tcps_rcvackbyte only if the flow were terminated correctly (in other words what was put in the Tx queue was transmitted and acked) 
* Total Tx L7 bytes are tcps_sndbyte_ok+tcps_sndrexmitbyte+tcps_sndprobe
* The Console/JSON does not show/sent zero counters

.Pseudo code tcp counters
[source,c]
----
            if ( (c->tcps_drops ==0) && 
                 (s->tcps_drops ==0) ){
               /* flow wasn't initiated due to drop of SYN too many times */
               
            /* client side */    
            assert(c->tcps_sndbyte==UPLOAD_BYTES);
            assert(c->tcps_rcvbyte==DOWNLOAD_BYTES);
            assert(c->tcps_rcvackbyte==UPLOAD_BYTES);

            /* server side */
            assert(s->tcps_rcvackbyte==DOWNLOAD_BYTES);
            assert(s->tcps_sndbyte==DOWNLOAD_BYTES);
            assert(s->tcps_rcvbyte==UPLOAD_BYTES);
            }
----

some rules for counters 
[source,c]
----
/* for client side */
  1. tcps_connects<=tcps_closed      /* Drop before socket is connected will be counted in different counter and will be counted in tcps_closed but not in tcps_connects */
  2. tcps_connattempt==tcps_closed

/* for server side */
1. tcps_accepts=tcps_connects=tcps_closed
  
----




==== TSO/LRO NIC support 

see manual for 

=== FAQ 

==== Why should I use TRex in this mode? 

ASTF mode can help to solve the following requirement: 

* Test realistic scenario on top of TCP when DUT is acting like TCP proxy
* Test realistic scenario in high scale (flows/bandwidth)
* flexibility to change the TCP/IP flow option 
* flexibility to emulate L7 application using Python API (e.g. Create many types of HTTP with different user-Agent field)
* Measure latency in high resolution (usec)

==== Why do I need to reload TRex server again with different flags to change to ASRF mode?
In theory, we could have supported that, but it required much more effort because the NIC memory configuration is fundamentally different. For example, in ASTF mode, we need to configure all the Rx queues to receive the packets and to configure the RSS to split the packets to different interface queues. While in Stateful we filter most of the packets and count them in hardware.

==== Is your core TCP implementation based on prior work?    
yes, BSD4.4-Lite version of TCP with a bug fixes from freeBSD and our changes for scale of high concurrent flow and performance.

==== What TCP RFCs are supported?

* RFC 793
* RFC 1122
* RFC 1323

Not implemented:  

* RFC 2018

==== Could you have a more recent TCP implementation?     
Yes, BSD4.4-Lite is from 1995 and does not have RFC 2018. We started as a POC and we plan to merge the latest freeBSD TCP core with our work

==== Can I reduce the active flows with ASTF mode, there are too many of them?
The short answer is no. The active(concurrent) flows derived from RTT and responses of the tested network/DUT. You can increase the number of active flows by adding delay instruction.

==== Will NAT64 work in ASTF mode?
Yes. just add --ipv6 to the CLI and Server side will handle IPv4 sockets

client side    NAT64      server side 

 IPv6           ->         IPv4 
 IPv6           <-         IPv4
 
example 

     client side IPv6
::16.0.0.1->::48.0.0.1   
                         DUT convert it to IPv4
                         
                                                 16.0.0.1->48.0.0.1 
                         DUT convert it to IPv6                      
  
                                                 16.0.0.1<-48.0.0.1 
                                                 
::16.0.0.1<-::48.0.0.1 

client works in IPV6                             server works on IPv4        
                                 
 
==== Is TSO/LRO NIC hardware optimization supported? 
Yes

==== Can I get the ASTF counters per port? 
We plan to add it in the interactive mode with RPC API. for now it is only global per all client and per server side. 



